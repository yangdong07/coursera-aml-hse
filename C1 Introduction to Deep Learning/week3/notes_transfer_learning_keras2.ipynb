{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Retraining\n",
    "\n",
    "主要是做练习时候的一个困惑： \n",
    "\n",
    "使用已经训练好的 InceptionV3，对新的图片分类问题进行训练，**很容易** 产生过拟合：对训练集，很容易达到100%的准确率，但是对测试集/验证集，准确率不到 50%，并且很难继续提升。 这说明什么，说明确实学习到了图片的特征，但是学习能力太强，产生了过拟合。\n",
    "\n",
    "google了一下，有些参考：\n",
    "\n",
    "- https://stackoverflow.com/questions/37605611/would-adding-dropout-help-reduce-overfitting-when-following-tensorflows-transfe\n",
    "\n",
    "- [Image Retraining](https://www.tensorflow.org/tutorials/image_retraining)\n",
    "\n",
    "这里按照 Image Retraining实际上也很简单，取了最后一层，加上新的训练层，对另一类图片重新进行训练。\n",
    "\n",
    "\n",
    "1. 准备图片，图片处理，数据集分割，以及提供batch方法\n",
    "2. 准备keras模型\n",
    "    1. 设置后 x 层重新训练，前 x 层不重新训练\n",
    "    2. 添加新的训练层\n",
    "    3. 添加评估方法\n",
    "3. 训练评估模型\n",
    "4. error analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import sys\n",
    "import urllib\n",
    "import tarfile\n",
    "import random\n",
    "import keras\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.python.util import compat\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "def reset_tf_session():\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    return K.get_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flowers102_tar_path = \"../readonly/week3/102flowers.tgz\"\n",
    "labels_mat_path = '../readonly/week3/imagelabels.mat'\n",
    "\n",
    "\n",
    "# 模型参数\n",
    "learning_rate = 0.01\n",
    "training_steps = 4000\n",
    "eval_step_interval = 100\n",
    "train_batch_size = 100\n",
    "validation_batch_size = 100\n",
    "test_batch_size = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备训练数据\n",
    "\n",
    "这里是102flowers数据，包括102种花。\n",
    "\n",
    "来源： <http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html>\n",
    "\n",
    "准备训练集、验证集和测试集以及标签。以及batch方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "# read filenames firectly from tar\n",
    "def get_all_filenames(tar_fn):\n",
    "    with tarfile.open(tar_fn) as f:\n",
    "        return [m.name for m in f.getmembers() if m.isfile()]\n",
    "\n",
    "all_files = sorted(get_all_filenames(\"../readonly/week3/102flowers.tgz\"))  # list all files in tar sorted by name\n",
    "all_labels = scipy.io.loadmat('../readonly/week3/imagelabels.mat')['labels'][0] - 1  # read class labels (0, 1, 2, ...)\n",
    "# all_files and all_labels are aligned now\n",
    "N_CLASSES = len(np.unique(all_labels))\n",
    "print(N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备模型\n",
    "\n",
    "### 2.1 使用 inception_v3模型\n",
    "\n",
    "tensorflow的model文件，参考这个文章： <https://www.tensorflow.org/extend/tool_developers/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 下载 inception_v3 模型文件 (.pb文件)\n",
    "\n",
    "data_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "model_dir = './tmp/imagenet'\n",
    "bottleneck_dir = '/tmp/bottleneck'\n",
    "model_file_name = 'classify_image_graph_def.pb'\n",
    "summaries_dir = '/tmp/retrain_logs2/'\n",
    "\n",
    "# 如果没有 './tmp/imagenet' 文件夹则创建\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "filename = data_url.split('/')[-1]\n",
    "filepath = os.path.join(model_dir, filename)\n",
    "\n",
    "# 进度条\n",
    "def _progress(count, block_size, total_size):\n",
    "    sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                     (filename,\n",
    "                      float(count * block_size) / float(total_size) * 100.0))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# 没有文件则下载\n",
    "if not os.path.exists(filepath):\n",
    "    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    tf.logging.info('Successfully downloaded %s %d bytes.', filename, statinfo.st_size)\n",
    "\n",
    "# 没有模型文件，则解压缩\n",
    "model_path = os.path.join(model_dir, model_file_name)\n",
    "if not os.path.exists(model_path):\n",
    "    print('Extracting file from ', filepath)\n",
    "    tarfile.open(filepath, 'r:gz').extractall(model_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path:  /tmp/imagenet/classify_image_graph_def.pb\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f1a607b0c88>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 从pb文件里面，创建 graph：\n",
    "print('Model path: ', model_path)\n",
    "\n",
    "def create_model_graph():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        print(graph)\n",
    "        with gfile.FastGFile(model_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck_tensor, resized_input_tensor = (tf.import_graph_def(\n",
    "                graph_def,\n",
    "                name='',\n",
    "                return_elements=['pool_3/_reshape:0', 'Mul:0']\n",
    "            ))\n",
    "    return graph, bottleneck_tensor, resized_input_tensor\n",
    "\n",
    "graph, bottleneck_tensor, resized_input_tensor =  create_model_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f1a607b0c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(1, 299, 299, 3), dtype=float32)\n",
      "Tensor(\"pool_3/_reshape:0\", shape=(1, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(resized_input_tensor)\n",
    "print(bottleneck_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 添加新的训练层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bottleneck_tensor_size = int(bottleneck_tensor.shape[-1])\n",
    "class_count = len(image_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "\n",
    "with graph.as_default():\n",
    "    # BottleneckInputPlaceholder, input =  bottlenck output\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "            bottleneck_tensor,\n",
    "            shape=[None, bottleneck_tensor_size],\n",
    "            name='BottleneckInputPlaceholder')\n",
    "\n",
    "        ground_truth_input = tf.placeholder(\n",
    "            tf.int64, [None], name='GroundTruthInput')\n",
    "\n",
    "    # Organizing the following ops so they are easier to see in TensorBoard.\n",
    "    with tf.name_scope('final_retrain_ops'):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal(\n",
    "                [bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "            variable_summaries(layer_weights)\n",
    "\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "            variable_summaries(layer_biases)\n",
    "            \n",
    "        # add dropout\n",
    "        with tf.name_scope('dropout'):\n",
    "            keep_prob = tf.placeholder_with_default(tf.constant(1.0), [], name='keep_prob')\n",
    "            drop = tf.nn.dropout(bottleneck_input, keep_prob)\n",
    "            \n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(drop, layer_weights) + layer_biases\n",
    "            tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "    # final output\n",
    "    final_tensor = tf.nn.softmax(logits, name='final_result')\n",
    "    tf.summary.histogram('activations', final_tensor)\n",
    "    \n",
    "# here we have : (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1.0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy 和 train：\n",
    "with graph.as_default():\n",
    "    # cross entropy\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=ground_truth_input, logits=logits)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "    # train step, optimizer\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估层\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(final_tensor, 1)\n",
    "            correct_prediction = tf.equal(prediction, ground_truth_input)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', evaluation_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 在原模型前面加上 `jepg_decoding` 层，用于处理图片输入\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在输入层添加 jpeg decoding层\n",
    "\n",
    "input_width = 299\n",
    "input_height = 299\n",
    "input_depth = 3\n",
    "input_mean = 128   # 256/2\n",
    "input_std = 128    # 256/2\n",
    "# resize and normalize ~(-0.5, 0.5)\n",
    "\n",
    "with graph.as_default():\n",
    "    jpeg_data_tensor = tf.placeholder(tf.string, name='DecodeJPGInput')\n",
    "    decoded_image = tf.image.decode_jpeg(jpeg_data_tensor, channels=input_depth)\n",
    "    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "    resize_shape = tf.stack([input_height, input_width])\n",
    "    resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "    resized_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                             resize_shape_as_int)\n",
    "    offset_image = tf.subtract(resized_image, input_mean)\n",
    "    decoded_image_tensor = tf.multiply(offset_image, 1.0 / input_std)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f1a607b0c88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpeg_data_tensor.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 计算并缓存 bottleneck 的输出（对所有图片）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 bottleneck层 的输出，并缓存。 主要是为了避免重复计算，加快训练速度\n",
    "\n",
    "def ensure_dir_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    \n",
    "def run_bottleneck_on_image(sess, image_data):\n",
    "    # image_data_tensor -> decoded_image_tensor | resized_input_tensor -> bottleneck_tensor\n",
    "    # image_data -> resized_input_values -> bottleneck_values\n",
    "    resized_input_values = sess.run(decoded_image_tensor, {jpeg_data_tensor: image_data})\n",
    "    # Then run it through the recognition network.\n",
    "    bottleneck_values = sess.run(bottleneck_tensor, {resized_input_tensor: resized_input_values})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values\n",
    "\n",
    "def create_bottleneck_file(sess, image_path, bottleneck_path):\n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fatal('File does not exist %s', image_path)\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(sess, image_data)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError('Error during processing file %s (%s)' % (image_path, str(e)))\n",
    "        \n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)\n",
    "\n",
    "ensure_dir_exists(bottleneck_dir)\n",
    "def get_or_create_bottleneck(sess, label_name, image_name):\n",
    "    image_path = os.path.join(image_dir, label_name, image_name)\n",
    "    bottleneck_path = os.path.join(bottleneck_dir, label_name, image_name + '.txt')\n",
    "    \n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        create_bottleneck_file(sess, image_path, bottleneck_path)\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneck_string = bottleneck_file.read()\n",
    "    bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    return bottleneck_values\n",
    "    \n",
    "    \n",
    "def cache_bottlenecks(sess):\n",
    "    how_many_bottlenecks = 0\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        sub_dir = os.path.join(bottleneck_dir, label_name)\n",
    "        ensure_dir_exists(sub_dir)\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(sess, label_name, unused_base_name)\n",
    "                how_many_bottlenecks += 1\n",
    "#                 if how_many_bottlenecks % 100 == 0:\n",
    "#                     tf.logging.info(str(how_many_bottlenecks) + ' bottleneck files created.')\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. 开始训练\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义batch 方法：\n",
    "\n",
    "def get_random_cached_bottlenecks(sess, batch_size, category):\n",
    "    \"\"\"Retrieves bottleneck values for cached images.\n",
    "    Args:\n",
    "      category: training, testing, or validation.\n",
    "    Returns:\n",
    "      List of bottleneck arrays, their corresponding ground truths, and the\n",
    "      relevant filenames.\n",
    "    \"\"\"\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if batch_size >= 0:\n",
    "        for unused_i in range(batch_size):\n",
    "            # random label\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = label_name = list(image_lists.keys())[label_index]\n",
    "            image_list = image_lists[label_name][category]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1) % len(image_list)\n",
    "            image_name = image_list[image_index]\n",
    "            bottleneck = get_or_create_bottleneck(sess, label_name, image_name)\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(label_index)\n",
    "            filenames.append(image_name)\n",
    "    else:\n",
    "        # Retrieve all bottlenecks.\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(image_lists[label_name][category]):\n",
    "                bottleneck = get_or_create_bottleneck(sess, label_name, image_name)\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(label_index)\n",
    "                filenames.append(image_name)\n",
    "                \n",
    "    return bottlenecks, ground_truths, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession(graph=graph)\n",
    "\n",
    "# summaries_dir = '/tmp/retrain_logs2/'\n",
    "\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_dir = '/tmp/retrain_logs2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:2018-03-20 23:21:07.670677: Step 0: Cross entropy = 1.599881, Train accuracy = 38.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:07.827266: Step 0: Validation accuracy = 31.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:11.690599: Step 100: Cross entropy = 1.187948, Train accuracy = 73.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:11.730365: Step 100: Validation accuracy = 76.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:15.606394: Step 200: Cross entropy = 1.030228, Train accuracy = 84.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:15.646094: Step 200: Validation accuracy = 72.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:19.494418: Step 300: Cross entropy = 0.911234, Train accuracy = 82.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:19.533439: Step 300: Validation accuracy = 77.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:23.396786: Step 400: Cross entropy = 0.785340, Train accuracy = 82.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:23.436329: Step 400: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:27.291526: Step 500: Cross entropy = 0.782731, Train accuracy = 78.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:27.330840: Step 500: Validation accuracy = 86.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:31.185401: Step 600: Cross entropy = 0.765814, Train accuracy = 84.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:31.224285: Step 600: Validation accuracy = 75.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:35.085442: Step 700: Cross entropy = 0.652724, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:35.124375: Step 700: Validation accuracy = 85.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:38.992273: Step 800: Cross entropy = 0.630315, Train accuracy = 82.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:39.031393: Step 800: Validation accuracy = 79.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:42.901195: Step 900: Cross entropy = 0.623940, Train accuracy = 86.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:42.940372: Step 900: Validation accuracy = 73.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:46.807858: Step 1000: Cross entropy = 0.616186, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:46.847248: Step 1000: Validation accuracy = 77.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:50.721651: Step 1100: Cross entropy = 0.583085, Train accuracy = 84.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:50.760788: Step 1100: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:54.639304: Step 1200: Cross entropy = 0.509197, Train accuracy = 89.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:54.678760: Step 1200: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:21:58.559787: Step 1300: Cross entropy = 0.537968, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:21:58.599019: Step 1300: Validation accuracy = 83.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:02.479891: Step 1400: Cross entropy = 0.539657, Train accuracy = 86.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:02.518987: Step 1400: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:06.398735: Step 1500: Cross entropy = 0.507316, Train accuracy = 84.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:06.437916: Step 1500: Validation accuracy = 89.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:10.324099: Step 1600: Cross entropy = 0.505946, Train accuracy = 88.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:10.363248: Step 1600: Validation accuracy = 79.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:14.254149: Step 1700: Cross entropy = 0.488898, Train accuracy = 87.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:14.293634: Step 1700: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:18.184312: Step 1800: Cross entropy = 0.607803, Train accuracy = 80.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:18.223791: Step 1800: Validation accuracy = 87.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:22.129306: Step 1900: Cross entropy = 0.488555, Train accuracy = 91.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:22.168787: Step 1900: Validation accuracy = 85.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:26.062396: Step 2000: Cross entropy = 0.676014, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:26.101657: Step 2000: Validation accuracy = 88.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:29.999639: Step 2100: Cross entropy = 0.481571, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:30.039295: Step 2100: Validation accuracy = 86.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:33.942046: Step 2200: Cross entropy = 0.465572, Train accuracy = 84.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:33.981948: Step 2200: Validation accuracy = 85.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:37.902439: Step 2300: Cross entropy = 0.454471, Train accuracy = 92.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:37.942348: Step 2300: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:41.846361: Step 2400: Cross entropy = 0.411954, Train accuracy = 91.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:41.885873: Step 2400: Validation accuracy = 87.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:45.816240: Step 2500: Cross entropy = 0.445555, Train accuracy = 90.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:45.856127: Step 2500: Validation accuracy = 91.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:49.773897: Step 2600: Cross entropy = 0.358678, Train accuracy = 92.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:49.813263: Step 2600: Validation accuracy = 78.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:53.730632: Step 2700: Cross entropy = 0.461058, Train accuracy = 82.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:53.770337: Step 2700: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:22:57.692971: Step 2800: Cross entropy = 0.413677, Train accuracy = 87.0%\n",
      "INFO:tensorflow:2018-03-20 23:22:57.732917: Step 2800: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:01.653602: Step 2900: Cross entropy = 0.467288, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:01.693248: Step 2900: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:05.622828: Step 3000: Cross entropy = 0.403337, Train accuracy = 88.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:05.662264: Step 3000: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:09.596330: Step 3100: Cross entropy = 0.411605, Train accuracy = 91.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:09.636004: Step 3100: Validation accuracy = 84.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:13.570241: Step 3200: Cross entropy = 0.491881, Train accuracy = 83.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:13.609993: Step 3200: Validation accuracy = 88.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:17.554631: Step 3300: Cross entropy = 0.398977, Train accuracy = 90.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:17.594460: Step 3300: Validation accuracy = 88.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:21.535598: Step 3400: Cross entropy = 0.326113, Train accuracy = 94.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:21.575678: Step 3400: Validation accuracy = 82.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:25.516751: Step 3500: Cross entropy = 0.354401, Train accuracy = 90.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:25.556136: Step 3500: Validation accuracy = 84.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:29.499524: Step 3600: Cross entropy = 0.495157, Train accuracy = 87.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:29.539498: Step 3600: Validation accuracy = 83.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:33.485566: Step 3700: Cross entropy = 0.394185, Train accuracy = 90.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:33.525022: Step 3700: Validation accuracy = 93.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:37.471837: Step 3800: Cross entropy = 0.380027, Train accuracy = 90.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:37.511311: Step 3800: Validation accuracy = 95.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:41.467447: Step 3900: Cross entropy = 0.425220, Train accuracy = 88.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:41.507024: Step 3900: Validation accuracy = 87.0% (N=100)\n",
      "INFO:tensorflow:2018-03-20 23:23:45.417333: Step 3999: Cross entropy = 0.342183, Train accuracy = 93.0%\n",
      "INFO:tensorflow:2018-03-20 23:23:45.457405: Step 3999: Validation accuracy = 80.0% (N=100)\n",
      "INFO:tensorflow:Final test accuracy = 88.1% (N=369)\n"
     ]
    }
   ],
   "source": [
    "training_steps= 4000\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # cache bottlenecks\n",
    "    cache_bottlenecks(sess)\n",
    "\n",
    "    # summary\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "    validation_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/validation')\n",
    "    train_saver = tf.train.Saver()\n",
    "\n",
    "    # \n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    for i in range(training_steps):\n",
    "        (train_bottlenecks, train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "                sess, FLAGS.train_batch_size, 'training')\n",
    "        # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "        # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "        train_summary, _ = sess.run(\n",
    "            [merged, train_step],\n",
    "            feed_dict={\n",
    "                bottleneck_input: train_bottlenecks,\n",
    "                ground_truth_input: train_ground_truth,\n",
    "                keep_prob: dropout_keep_prob,\n",
    "            })\n",
    "        train_writer.add_summary(train_summary, i)\n",
    "\n",
    "        # Every so often, print out how well the graph is training.\n",
    "        is_last_step = (i + 1 == training_steps)\n",
    "        if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "            train_accuracy, cross_entropy_value = sess.run(\n",
    "                [evaluation_step, cross_entropy_mean],\n",
    "                feed_dict={\n",
    "                    bottleneck_input: train_bottlenecks,\n",
    "                    ground_truth_input: train_ground_truth\n",
    "                })\n",
    "            tf.logging.info('%s: Step %d: Cross entropy = %f, Train accuracy = %.1f%%' % (\n",
    "                datetime.now(), i, cross_entropy_value, train_accuracy * 100))\n",
    "            \n",
    "            validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                get_random_cached_bottlenecks(sess, FLAGS.validation_batch_size, 'validation'))\n",
    "\n",
    "            # Run a validation step and capture training summaries for TensorBoard\n",
    "            # with the `merged` op.\n",
    "            validation_summary, validation_accuracy = sess.run(\n",
    "                [merged, evaluation_step],\n",
    "                feed_dict={\n",
    "                    bottleneck_input: validation_bottlenecks,\n",
    "                    ground_truth_input: validation_ground_truth\n",
    "                })\n",
    "            validation_writer.add_summary(validation_summary, i)\n",
    "            tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                            (datetime.now(), i, validation_accuracy * 100,\n",
    "                             len(validation_bottlenecks)))\n",
    "    # 这个用于保存session中的模型和参数信息\n",
    "    #     train_saver.save(sess, CHECKPOINT_NAME)\n",
    "\n",
    "    #     # We've completed all our training, so run a final test evaluation on\n",
    "    #     # some new images we haven't used before.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(sess, FLAGS.test_batch_size, 'testing'))\n",
    "        \n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={\n",
    "            bottleneck_input: test_bottlenecks,\n",
    "            ground_truth_input: test_ground_truth\n",
    "        })\n",
    "    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                    (test_accuracy * 100, len(test_bottlenecks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "没有 Dropout的时候： INFO:tensorflow:Final test accuracy = 91.6% (N=369)\n",
    "\n",
    "加了一层dropout训练（keep_prob=0.8)： INFO:tensorflow:Final test accuracy = 91.9% (N=369)\n",
    "\n",
    "提升了一点点。。\n",
    "\n",
    "keep_prob=0.5： INFO:tensorflow:Final test accuracy = 92.7% (N=369)\n",
    "略有提升\n",
    "\n",
    "将learning rate 改成0.001， Final test accuracy = 88.1% (N=369)  ， 会下降。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
